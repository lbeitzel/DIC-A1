{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSE 587: PREDICTIVE ANALYTICS PROJECT\n",
    "\n",
    "#pandas and numpy imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data Import\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-90d1d0bfd0b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#X and Y data separation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## DATA PREPROCESSING\n",
    "\n",
    "#X and Y data separation\n",
    "data = df.to_numpy()\n",
    "X = data[:,0:48]\n",
    "Y = data[:,48:49].flatten()\n",
    "\n",
    "##Normalized data\n",
    "X_min = np.min(X,axis = 0)\n",
    "X_max = np.max(X,axis = 0)\n",
    "X_minMat = np.tile(X_min, (X.shape[0],1))\n",
    "X_maxMat = np.tile(X_max, (X.shape[0],1))\n",
    "X_normal = np.true_divide(X-X_minMat, X_maxMat-X_minMat)\n",
    "\n",
    "#Splitting data 80-20 into training and testing\n",
    "training_ind = np.random.rand(len(X_normal)) <= 0.8\n",
    "X_train = X_normal[training_ind]\n",
    "X_test = X_normal[~training_ind]\n",
    "Y_train = Y[training_ind]\n",
    "Y_test = Y[~training_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807132459970888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### KNN ALGORITHM USING COSINE DISTANCE\n",
    "\n",
    "#Select X_train and X_test to test on which has already been normalized\n",
    "X_train = X_train[:,0:48]\n",
    "Y_train = Y_train\n",
    "X_test = X_test[:,0:48]\n",
    "Y_test = Y_test\n",
    "\n",
    "#Normalize every row to create unit vectors of data\n",
    "X_train_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_train)\n",
    "X_test_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_test)\n",
    "\n",
    "C = np.transpose(np.tile(X_train_L1norm, (X_train.shape[1],1)))\n",
    "D = np.transpose(np.tile(X_test_L1norm, (X_test.shape[1],1)))\n",
    "\n",
    "X_train_final = np.transpose(np.true_divide(X_train,C))\n",
    "X_test_final = np.true_divide(X_test,D)\n",
    "\n",
    "#Find the cosine product \n",
    "dist = np.dot(X_test_final, X_train_final)\n",
    "\n",
    "#Attach true label with distances and get Cosine distance from Cosine Similarity\n",
    "trueLabel = np.tile(Y_train, (X_test_final.shape[0],1))\n",
    "ones = np.ones((X_test.shape[0],X_train.shape[0]))\n",
    "Dist = np.subtract(ones,dist)\n",
    "Dist = np.array([Dist, trueLabel])\n",
    "\n",
    "#Sort 3d array so labels will match sorted distances\n",
    "I, J, K = np.ogrid[tuple(map(slice, Dist.shape))]\n",
    "newK = np.argsort(Dist[0],axis=-1)\n",
    "Dist = Dist[I, J, newK]\n",
    "\n",
    "#Select k and choose top k labels\n",
    "k = 14\n",
    "topK = Dist[1,:,0:k]\n",
    "topK = topK.astype(int)\n",
    "\n",
    "#Keep count of most frequent label for each test comparison\n",
    "Y_pred = np.array([])\n",
    "for vector in topK:\n",
    "    counts = np.bincount(vector)\n",
    "    majority = np.argmax(counts)\n",
    "    Y_pred = np.append(Y_pred,majority)\n",
    "    \n",
    "#Check accuracy using sklearns\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "display(accuracy_score(y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-64e9eb9acf1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# feature scaling using min max normilization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#****************************Part2(Scikit)**********************************\n",
    "#KNN \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics \n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# feature scaling using min max normilization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=4)\n",
    "#knn logic\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(X_train,Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "display(accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# feature scaling using min max normilization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "#setting up the classifier \n",
    "svclass = SVC(kernel='linear')\n",
    "svclass.fit(X_train,Y_train)\n",
    "#making the prediction \n",
    "y_pred = svclass.predict(X_test)\n",
    "display(accuracy_score(Y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
