{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSE 587: PREDICTIVE ANALYTICS PROJECT\n",
    "\n",
    "#pandas and numpy imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data Import\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREPROCESSING\n",
    "\n",
    "#X and Y data separation\n",
    "data = df.to_numpy()\n",
    "X = data[:,0:48]\n",
    "Y = data[:,48:49].flatten()\n",
    "\n",
    "##Normalized data\n",
    "X_min = np.min(X,axis = 0)\n",
    "X_max = np.max(X,axis = 0)\n",
    "X_minMat = np.tile(X_min, (X.shape[0],1))\n",
    "X_maxMat = np.tile(X_max, (X.shape[0],1))\n",
    "X_normal = np.true_divide(X-X_minMat, X_maxMat-X_minMat)\n",
    "\n",
    "#Splitting data 80-20 into training and testing\n",
    "training_ind = np.random.rand(len(X_normal)) <= 0.8\n",
    "X_train = X_normal[training_ind]\n",
    "X_test = X_normal[~training_ind]\n",
    "Y_train = Y[training_ind]\n",
    "Y_test = Y[~training_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838248102525818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### KNN ALGORITHM USING COSINE DISTANCE\n",
    "\n",
    "#Select X_train and X_test to test on which has already been normalized\n",
    "X_train = X_train[:,0:48]\n",
    "Y_train = Y_train\n",
    "X_test = X_test[:,0:48]\n",
    "Y_test = Y_test\n",
    "\n",
    "#Normalize every row to create unit vectors of data\n",
    "X_train_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_train)\n",
    "X_test_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_test)\n",
    "\n",
    "C = np.transpose(np.tile(X_train_L1norm, (X_train.shape[1],1)))\n",
    "D = np.transpose(np.tile(X_test_L1norm, (X_test.shape[1],1)))\n",
    "\n",
    "X_train_final = np.transpose(np.true_divide(X_train,C))\n",
    "X_test_final = np.true_divide(X_test,D)\n",
    "\n",
    "#Find the cosine product \n",
    "dist = np.dot(X_test_final, X_train_final)\n",
    "\n",
    "#Attach true label with distances and get Cosine distance from Cosine Similarity\n",
    "trueLabel = np.tile(Y_train, (X_test_final.shape[0],1))\n",
    "ones = np.ones((X_test.shape[0],X_train.shape[0]))\n",
    "Dist = np.subtract(ones,dist)\n",
    "Dist = np.array([Dist, trueLabel])\n",
    "\n",
    "#Sort 3d array so labels will match sorted distances\n",
    "I, J, K = np.ogrid[tuple(map(slice, Dist.shape))]\n",
    "newK = np.argsort(Dist[0],axis=-1)\n",
    "Dist = Dist[I, J, newK]\n",
    "\n",
    "#Select k and choose top k labels\n",
    "k = 14\n",
    "topK = Dist[1,:,0:k]\n",
    "topK = topK.astype(int)\n",
    "\n",
    "#Keep count of most frequent label for each test comparison\n",
    "Y_pred = np.array([])\n",
    "for vector in topK:\n",
    "    counts = np.bincount(vector)\n",
    "    majority = np.argmax(counts)\n",
    "    Y_pred = np.append(Y_pred,majority)\n",
    "    \n",
    "#Check accuracy using sklearns\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "display(accuracy_score(y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_number= \n",
    "counts = np.array([[1,2,3,4,5],[1,2,3,4,5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98388671875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#****************************Part2(Scikit)**********************************\n",
    "#KNN \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics \n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# feature scaling using min max normilization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=4)\n",
    "#knn logic\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(X_train,Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "display(accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8941650390625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# feature scaling using min max normilization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "#setting up the classifier \n",
    "svclass = SVC(kernel='linear')\n",
    "svclass.fit(X_train,Y_train)\n",
    "#making the prediction \n",
    "y_pred = svclass.predict(X_test)\n",
    "display(accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825439453125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "# setting up gini impurity \n",
    "giniImp = DecisionTreeClassifier(criterion = \"gini\", random_state=100)\n",
    "giniImp.fit(X_train,Y_train)\n",
    "# make prediction \n",
    "y_pred = giniImp.predict(X_test)\n",
    "# accuracy score \n",
    "display(metrics.accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna Menon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7171630859375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X = data[:,0:48]\n",
    "Y = data[:, 48:49].flatten()\n",
    "# feature scaling using min max normilization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#splitting the data \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "# beginning of LR logic\n",
    "lrmodel = LogisticRegression(solver = 'liblinear', random_state= 4)\n",
    "lrmodel.fit(X_train,Y_train)\n",
    "# Making the prediction\n",
    "y_pred = lrmodel.predict(X_test)\n",
    "display(metrics.accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
