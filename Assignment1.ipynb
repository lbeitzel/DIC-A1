{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   0             1         2             3             4  \\\n",
       "0     -3.014000e-06 -4.413800e-05 -0.000278 -6.710100e-06 -1.504300e-05   \n",
       "1     -4.532700e-06 -2.720700e-05  0.000115  2.347100e-07 -2.236600e-05   \n",
       "2     -9.615600e-07  1.529200e-06 -0.000006  4.854600e-06  5.964500e-06   \n",
       "3      1.856800e-06 -1.302700e-05 -0.000139 -2.323100e-06 -5.872700e-05   \n",
       "4     -1.833400e-06  6.669700e-06  0.000011 -4.316300e-06  1.245300e-06   \n",
       "5     -3.156200e-06 -7.670600e-06  0.000140  6.788300e-07 -3.355900e-06   \n",
       "6     -3.095400e-06 -2.104300e-06 -0.000012  2.398000e-06  3.838200e-06   \n",
       "7     -7.541000e-06 -6.777400e-06 -0.000027  6.371600e-07 -2.189700e-05   \n",
       "8      1.769800e-06 -6.489500e-07  0.000056  2.470400e-06 -9.469400e-06   \n",
       "9      1.405500e-05  4.458900e-05  0.000095 -5.255000e-06  1.053300e-04   \n",
       "10     5.419300e-06 -1.099400e-05 -0.000060  3.271200e-06 -3.325100e-06   \n",
       "11    -1.295200e-05 -1.622300e-05  0.000275 -1.244000e-05 -5.810200e-05   \n",
       "12    -1.019400e-05 -3.057000e-06 -0.000261  1.313900e-06 -8.207200e-06   \n",
       "13    -1.439500e-05  7.205100e-05 -0.000130 -1.299500e-05  5.177100e-05   \n",
       "14     4.249400e-06 -4.084100e-05  0.000234 -2.910500e-08 -3.670900e-05   \n",
       "15     5.146300e-06  1.250100e-05 -0.000082 -1.002700e-05 -8.456300e-06   \n",
       "16    -5.621100e-06 -4.688500e-05  0.000138 -2.466900e-05 -7.077700e-05   \n",
       "17     1.379000e-05 -2.923500e-06 -0.000090 -1.056700e-05 -1.023300e-05   \n",
       "18     1.544100e-05  1.560700e-04  0.000303 -5.227900e-07 -1.747600e-05   \n",
       "19     1.472500e-05  5.302500e-05  0.000599 -1.628000e-05  7.752600e-05   \n",
       "20     1.515200e-06  6.292500e-06  0.000138 -8.260100e-08  2.749200e-05   \n",
       "21    -2.075900e-07 -6.886000e-06 -0.000009  8.102200e-06  5.924500e-05   \n",
       "22     1.755600e-05  5.646400e-05 -0.000024  5.842200e-06  2.392700e-05   \n",
       "23    -1.455800e-06 -2.507000e-06  0.000007 -3.398100e-06  1.134700e-06   \n",
       "24     1.261300e-05  4.350300e-05 -0.000449 -6.959800e-06  2.968700e-05   \n",
       "25    -2.876000e-05 -9.470700e-05 -0.000002 -1.124200e-05 -2.774000e-05   \n",
       "26    -4.937700e-06  3.696500e-06 -0.000010  2.780900e-06  1.790300e-06   \n",
       "27    -3.397500e-06  1.205800e-06  0.000388 -1.519500e-05 -3.983600e-05   \n",
       "28    -2.161200e-05 -7.543400e-05  0.000156 -1.705100e-05 -4.497300e-06   \n",
       "29     4.632600e-06  5.792200e-05 -0.000164 -1.088800e-06  2.298400e-05   \n",
       "...             ...           ...       ...           ...           ...   \n",
       "40926 -1.270000e-05 -1.066600e-05  0.000289 -7.873300e-06 -3.496900e-05   \n",
       "40927  5.888100e-06  6.657600e-05 -0.000442  7.572000e-06  2.123400e-05   \n",
       "40928 -5.684500e-07 -4.160500e-07  0.000005  5.651700e-07  2.996000e-06   \n",
       "40929  3.964000e-06  3.560300e-05  0.000462  9.736300e-06 -4.388200e-05   \n",
       "40930 -6.776600e-07  2.134900e-05  0.000050  1.798000e-06  4.340600e-06   \n",
       "40931 -2.667700e-05 -3.264200e-05  0.000434 -1.448600e-05 -2.754900e-05   \n",
       "40932  1.549700e-07 -2.081500e-05 -0.000028  3.187700e-06  1.979700e-05   \n",
       "40933 -3.085200e-06 -4.220000e-06 -0.000130 -1.337500e-06  7.551500e-06   \n",
       "40934 -1.119600e-05  6.945300e-05 -0.000078 -9.326100e-06 -4.876300e-05   \n",
       "40935 -4.287000e-06 -3.065900e-05  0.000132  8.306500e-06 -1.764300e-05   \n",
       "40936 -3.272600e-06  4.829200e-07 -0.000014 -3.942500e-06 -3.800300e-06   \n",
       "40937  7.206800e-06  3.246200e-05  0.000067  1.308800e-06  3.256900e-05   \n",
       "40938  3.051100e-06  2.081800e-05 -0.000492 -1.228200e-05  3.423800e-05   \n",
       "40939 -1.334300e-05 -1.160400e-04  0.000281 -2.337100e-06 -1.968700e-05   \n",
       "40940 -2.381100e-05 -1.375400e-05 -0.000265 -1.156400e-05 -1.714900e-05   \n",
       "40941 -6.425600e-06  8.716400e-05  0.000127  3.102100e-06  4.900900e-05   \n",
       "40942 -1.076800e-06  6.241100e-06  0.000066 -5.836200e-06 -5.552600e-06   \n",
       "40943 -3.150600e-06  1.300300e-05  0.000034  2.320500e-05  1.071100e-04   \n",
       "40944 -5.969200e-06 -5.258800e-05 -0.000083 -4.059900e-06  1.437000e-05   \n",
       "40945 -1.875500e-06 -6.300800e-07 -0.000007  2.698100e-06 -3.785900e-06   \n",
       "40946 -3.943800e-06  2.295400e-06 -0.000011 -8.780700e-07 -6.726200e-06   \n",
       "40947 -1.091300e-05  2.212600e-05 -0.000027 -1.069000e-05 -2.461800e-08   \n",
       "40948 -7.237800e-06 -6.078900e-06 -0.000198 -3.938800e-06  7.539700e-05   \n",
       "40949 -1.435800e-05 -2.645300e-05  0.000008 -1.840900e-06  9.721200e-06   \n",
       "40950 -2.199600e-05  1.287300e-06 -0.000048  2.136800e-06  4.272700e-05   \n",
       "40951 -1.124200e-05 -4.912300e-05  0.000240 -3.430900e-06 -3.712600e-05   \n",
       "40952  2.557900e-05 -6.380400e-05  0.000317 -1.022400e-05 -3.991500e-05   \n",
       "40953 -5.511600e-06 -2.435200e-05 -0.000420  2.083000e-07 -2.797300e-05   \n",
       "40954 -3.943400e-06  8.596000e-07 -0.000016  1.831200e-06 -7.038100e-07   \n",
       "40955 -6.234500e-06 -6.602100e-05  0.000106 -1.974200e-05  6.124000e-06   \n",
       "\n",
       "                  5         6         7         8         9  ...       39  \\\n",
       "0     -1.128500e-04  0.010787  0.010831  0.011108  0.002458  ... -0.71593   \n",
       "1     -3.181600e-04  0.025578  0.025605  0.025490  0.025175  ... -0.61186   \n",
       "2     -1.482000e-05  0.006317  0.006315  0.006321 -0.035309  ... -0.48252   \n",
       "3      1.838500e-04  0.008755  0.008768  0.008907 -0.041292  ... -0.69714   \n",
       "4      1.027500e-05  0.021416  0.021409  0.021399 -0.018570  ... -0.48441   \n",
       "5      4.588100e-05  0.013375  0.013383  0.013243 -0.029067  ... -0.69482   \n",
       "6      1.895500e-05  0.018476  0.018478  0.018490  0.014458  ... -0.58091   \n",
       "7     -9.719800e-05  0.017008  0.017015  0.017042 -0.022280  ... -0.83991   \n",
       "8     -6.814700e-06  0.027188  0.027188  0.027132  0.019315  ... -0.53582   \n",
       "9      4.075200e-04 -0.031090 -0.031135 -0.031230 -0.006835  ... -0.48847   \n",
       "10    -6.811100e-05  0.031485  0.031496  0.031557  0.024989  ... -0.60739   \n",
       "11    -3.624100e-04  0.019455  0.019471  0.019196  0.033110  ... -0.62059   \n",
       "12    -4.266300e-05 -0.020941 -0.020938 -0.020677 -0.021530  ... -0.74947   \n",
       "13     2.190500e-04 -0.024895 -0.024967 -0.024837 -0.024980  ... -0.72983   \n",
       "14    -6.689100e-04  0.032450  0.032490  0.032256  0.100120  ... -0.55304   \n",
       "15    -5.719500e-05  0.013219  0.013206  0.013288 -0.036136  ... -0.83960   \n",
       "16    -2.514400e-04  0.031802  0.031848  0.031710  0.030024  ... -0.62676   \n",
       "17     2.064200e-05  0.022277  0.022280  0.022370  0.064244  ... -0.70768   \n",
       "18     2.915100e-04  0.016687  0.016531  0.016228 -0.024502  ... -0.51306   \n",
       "19     1.884300e-05  0.054627  0.054574  0.053974  0.069487  ... -0.70383   \n",
       "20     3.410700e-05  0.010126  0.010120  0.009982 -0.041339  ... -0.80459   \n",
       "21    -1.916900e-04  0.029895  0.029902  0.029912  0.077748  ... -0.67605   \n",
       "22     2.675900e-04  0.013097  0.013040  0.013065 -0.027841  ... -0.52653   \n",
       "23    -3.452300e-05  0.026666  0.026669  0.026661 -0.029616  ... -0.50591   \n",
       "24     8.742000e-05  0.003230  0.003187  0.003636  0.000877  ... -0.64963   \n",
       "25    -1.109800e-04 -0.113830 -0.113740 -0.113730 -0.136480  ... -0.71752   \n",
       "26     1.303500e-05 -0.108360 -0.108360 -0.108350 -0.204220  ... -0.44703   \n",
       "27    -8.970200e-05  0.029226  0.029225  0.028836  0.022370  ... -0.70419   \n",
       "28    -3.579600e-05  0.027587  0.027663  0.027506  0.028954  ... -0.51870   \n",
       "29    -6.262800e-05  0.048492  0.048434  0.048597  0.070925  ... -0.74044   \n",
       "...             ...       ...       ...       ...       ...  ...      ...   \n",
       "40926 -1.248600e-06  0.027839  0.027850  0.027561  0.024592  ... -0.66774   \n",
       "40927  6.955100e-05  0.007325  0.007259  0.007701 -0.032621  ... -0.66519   \n",
       "40928 -6.628300e-06  0.043303  0.043303  0.043298  0.023808  ... -0.41600   \n",
       "40929 -3.338800e-04  0.004553  0.004517  0.004055 -0.031935  ... -0.66713   \n",
       "40930  4.667300e-05  0.045119  0.045098  0.045048  0.106190  ... -0.79729   \n",
       "40931  7.817600e-04 -0.074992 -0.074959 -0.075393 -0.201040  ... -0.56382   \n",
       "40932 -2.116600e-04  0.002695  0.002715  0.002743 -0.025553  ... -0.62029   \n",
       "40933 -6.938900e-05  0.009060  0.009065  0.009194  0.005943  ... -0.68071   \n",
       "40934 -2.661700e-04  0.025272  0.025202  0.025281  0.009003  ... -0.55296   \n",
       "40935 -7.664400e-05  0.016970  0.017001  0.016869  0.044373  ... -0.82323   \n",
       "40936 -2.217100e-06 -0.038857 -0.038858 -0.038843 -0.016560  ... -0.54368   \n",
       "40937  3.032100e-04  0.008102  0.008070  0.008003 -0.032286  ... -0.71414   \n",
       "40938 -2.359300e-05  0.052218  0.052197  0.052689  0.069074  ... -0.69648   \n",
       "40939  2.736000e-04  0.014945  0.015061  0.014780 -0.023057  ... -0.64726   \n",
       "40940 -3.091900e-04  0.037505  0.037519  0.037783 -0.000810  ... -0.52575   \n",
       "40941  1.472800e-04  0.009696  0.009609  0.009482 -0.019009  ... -0.68236   \n",
       "40942 -2.038600e-05  0.010295  0.010289  0.010223  0.007290  ... -0.67326   \n",
       "40943  7.194700e-05  0.022244  0.022231  0.022197 -0.022602  ... -0.68012   \n",
       "40944  1.290700e-04  0.013631  0.013683  0.013766  0.057950  ... -0.64358   \n",
       "40945 -3.050800e-06  0.017018  0.017019  0.017025 -0.022404  ... -0.50065   \n",
       "40946  3.633100e-07  0.006318  0.006316  0.006327  0.006644  ... -0.59043   \n",
       "40947 -3.617800e-05 -0.020441 -0.020464 -0.020437 -0.030461  ... -0.67020   \n",
       "40948 -6.457000e-05  0.021229  0.021235  0.021433 -0.042728  ... -0.67459   \n",
       "40949 -1.134200e-04 -0.085772 -0.085745 -0.085753 -0.193200  ... -0.75059   \n",
       "40950  3.056500e-04 -0.061116 -0.061117 -0.061070 -0.168850  ... -0.58690   \n",
       "40951 -1.492400e-05  0.012029  0.012078  0.011838  0.006625  ... -0.69735   \n",
       "40952 -1.161000e-04 -0.000648 -0.000584 -0.000901  0.012162  ... -0.63325   \n",
       "40953 -6.997400e-05  0.032105  0.032129  0.032549  0.013156  ... -0.86522   \n",
       "40954  1.422800e-05 -0.106190 -0.106190 -0.106170 -0.199550  ... -0.47014   \n",
       "40955 -1.097400e-04  0.017258  0.017324  0.017218 -0.037468  ... -0.62898   \n",
       "\n",
       "              40       41      42      43      44      45      46      47  48  \n",
       "0       1.661700  12.1770 -1.5040 -1.5041 -1.5044 -1.4984 -1.4985 -1.4984   5  \n",
       "1       2.157400   6.7002 -1.4944 -1.4944 -1.4940 -1.5048 -1.5048 -1.5049   8  \n",
       "2       6.085900  16.2140 -1.4998 -1.4998 -1.4998 -1.4975 -1.4975 -1.4975   9  \n",
       "3       0.612700   5.6592 -1.5036 -1.5036 -1.5033 -1.4945 -1.4945 -1.4944   9  \n",
       "4       4.342000  12.3630 -1.4993 -1.4993 -1.4993 -1.4978 -1.4978 -1.4978   6  \n",
       "5       2.848900   6.3090 -1.4974 -1.4974 -1.4973 -1.4978 -1.4978 -1.4979   6  \n",
       "6       2.495500   6.3704 -1.4979 -1.4979 -1.4979 -1.4982 -1.4982 -1.4982   5  \n",
       "7      43.235000  12.8280 -1.4985 -1.4986 -1.4985 -1.5003 -1.5003 -1.5004   9  \n",
       "8      33.027000   8.6757 -1.4981 -1.4981 -1.4981 -1.4981 -1.4981 -1.4981   5  \n",
       "9       7.529300   8.1841 -1.5062 -1.5061 -1.5061 -1.4986 -1.4986 -1.4978  10  \n",
       "10      1.659100  13.3470 -1.4983 -1.4983 -1.4983 -1.4969 -1.4969 -1.4969   8  \n",
       "11      0.983610   3.6004 -1.5008 -1.5007 -1.5004 -1.4994 -1.4994 -1.4995   5  \n",
       "12     14.191000   6.4254 -1.5002 -1.5002 -1.5003 -1.4977 -1.4977 -1.4977   2  \n",
       "13      1.973400   7.5047 -1.5058 -1.5060 -1.5055 -1.4965 -1.4965 -1.4964  10  \n",
       "14      0.804960  10.2080 -1.4980 -1.4981 -1.4977 -1.5006 -1.5006 -1.5000   7  \n",
       "15      9.702100  10.2290 -1.5022 -1.5022 -1.5022 -1.4974 -1.4974 -1.4973   6  \n",
       "16      2.190300   8.7908 -1.4973 -1.4975 -1.4972 -1.5029 -1.5029 -1.5030   8  \n",
       "17      2.473900   5.1086 -1.4997 -1.4997 -1.4998 -1.5001 -1.5001 -1.4999   4  \n",
       "18      3.364600   4.6597 -1.5057 -1.5057 -1.5059 -1.4954 -1.4955 -1.4954   1  \n",
       "19      1.074000   3.4122 -1.5057 -1.5057 -1.5060 -1.5013 -1.5014 -1.5010   7  \n",
       "20     23.178000   7.0542 -1.5004 -1.5004 -1.5002 -1.5000 -1.5001 -1.5000   6  \n",
       "21      0.768940   7.4036 -1.5005 -1.5005 -1.5004 -1.4938 -1.4939 -1.4938   7  \n",
       "22      4.417700   4.6212 -1.5038 -1.5039 -1.5034 -1.4987 -1.4988 -1.4988   6  \n",
       "23      4.359700  19.5660 -1.4975 -1.4975 -1.4975 -1.4981 -1.4981 -1.4981   1  \n",
       "24      2.561200   3.7242 -1.5037 -1.5037 -1.5040 -1.5001 -1.5001 -1.5000   3  \n",
       "25      0.525760   4.6637 -1.5067 -1.5065 -1.5063 -1.4956 -1.4956 -1.4953  11  \n",
       "26      9.978700   7.6281 -1.4986 -1.4986 -1.4985 -1.4976 -1.4976 -1.4976  11  \n",
       "27      0.622390   3.5091 -1.5000 -1.5001 -1.4991 -1.5006 -1.5007 -1.5006   5  \n",
       "28      7.719800   3.6361 -1.5082 -1.5082 -1.5079 -1.4975 -1.4975 -1.4973   4  \n",
       "29      4.271600  13.3960 -1.5012 -1.5014 -1.5010 -1.4990 -1.4991 -1.4988   7  \n",
       "...          ...      ...     ...     ...     ...     ...     ...     ...  ..  \n",
       "40926   0.020123   7.7290 -1.5046 -1.5047 -1.5045 -1.4957 -1.4956 -1.4954   5  \n",
       "40927   0.219580   1.9313 -1.5073 -1.5074 -1.5072 -1.4983 -1.4983 -1.4979   6  \n",
       "40928  20.646000  67.8930 -1.4991 -1.4991 -1.4991 -1.4981 -1.4981 -1.4981   8  \n",
       "40929   0.974080   5.8591 -1.5094 -1.5095 -1.5089 -1.4983 -1.4983 -1.4984   6  \n",
       "40930  13.103000  11.1040 -1.5025 -1.5025 -1.5023 -1.4991 -1.4990 -1.4990   7  \n",
       "40931   3.796200   9.7536 -1.4953 -1.4953 -1.4955 -1.5017 -1.5017 -1.5018  11  \n",
       "40932   3.274500   4.4495 -1.5023 -1.5024 -1.5021 -1.4961 -1.4960 -1.4960   6  \n",
       "40933  12.420000   4.2988 -1.5006 -1.5007 -1.5008 -1.4967 -1.4967 -1.4966   3  \n",
       "40934   6.016600  11.3760 -1.5051 -1.5052 -1.5051 -1.4942 -1.4942 -1.4939   5  \n",
       "40935   9.192700  11.0710 -1.5008 -1.5008 -1.5006 -1.4975 -1.4975 -1.4974   4  \n",
       "40936   8.751100  12.5800 -1.4966 -1.4966 -1.4966 -1.4988 -1.4987 -1.4987  10  \n",
       "40937   1.098500   5.6883 -1.4989 -1.4989 -1.4988 -1.5028 -1.5029 -1.5028   6  \n",
       "40938  -0.542700   5.0449 -1.5038 -1.5038 -1.5034 -1.5015 -1.5016 -1.5011   7  \n",
       "40939   0.464170   6.9366 -1.4964 -1.4966 -1.4967 -1.5020 -1.5020 -1.5015   9  \n",
       "40940   1.134400   6.4793 -1.5029 -1.5029 -1.5025 -1.4914 -1.4914 -1.4917   8  \n",
       "40941   2.099400   3.7437 -1.4973 -1.4975 -1.4976 -1.5037 -1.5037 -1.5037   6  \n",
       "40942   1.667400   3.6798 -1.4992 -1.4992 -1.4992 -1.4973 -1.4972 -1.4973   3  \n",
       "40943  11.181000   9.0156 -1.4989 -1.4989 -1.4990 -1.5010 -1.5011 -1.5006   1  \n",
       "40944   1.410100   6.4214 -1.5042 -1.5041 -1.5039 -1.4981 -1.4981 -1.4981   4  \n",
       "40945   5.803500   7.9897 -1.4965 -1.4965 -1.4965 -1.4966 -1.4966 -1.4966   9  \n",
       "40946  11.030000  11.0190 -1.4964 -1.4964 -1.4964 -1.4984 -1.4983 -1.4983   3  \n",
       "40947   3.524000  22.7150 -1.4989 -1.4990 -1.4989 -1.5003 -1.5003 -1.5004   2  \n",
       "40948   2.679900   1.9969 -1.5081 -1.5081 -1.5079 -1.4975 -1.4975 -1.4970   1  \n",
       "40949  16.526000  27.4730 -1.5002 -1.5003 -1.5004 -1.4993 -1.4993 -1.4988  11  \n",
       "40950   4.416300   7.6787 -1.5042 -1.5042 -1.5040 -1.4938 -1.4938 -1.4940  11  \n",
       "40951   0.998800   8.7558 -1.5002 -1.5002 -1.5006 -1.4996 -1.4996 -1.4995   5  \n",
       "40952   2.838000   2.7161 -1.5040 -1.5041 -1.5028 -1.4948 -1.4947 -1.4945   3  \n",
       "40953   6.553800  11.4080 -1.5006 -1.5006 -1.5008 -1.4989 -1.4989 -1.4989   8  \n",
       "40954  37.978000  41.8290 -1.4977 -1.4977 -1.4977 -1.4988 -1.4987 -1.4988  11  \n",
       "40955   0.968380   5.3587 -1.5051 -1.5050 -1.5046 -1.4954 -1.4955 -1.4954   9  \n",
       "\n",
       "[40956 rows x 49 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "training_ind = np.random.rand(len(data)) <= 0.8\n",
    "training = data[training_ind]\n",
    "testing = data[~training_ind]\n",
    "X_train = training[0:32734, 0:48]\n",
    "Y_train = training[0:32734, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:8222, 0:48]\n",
    "Y_test = testing[0:8222, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "k = 5\n",
    "print(KNN(X_train, X_test, Y_train, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "     \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = training[0:8000, 0:20]\n",
    "Y_train = training[0:8000, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:2000, 0:20]\n",
    "Y_test = testing[0:2000, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "k = 10\n",
    "\n",
    "y_pred = np.array([])\n",
    "for point in X_test:\n",
    "        dist = np.array([])\n",
    "        for row in X_train:\n",
    "            d = np.sqrt(np.sum((point-row)**2))\n",
    "            dist = np.append(dist, d)\n",
    "        attach = np.vstack((dist, Y_train))\n",
    "        sortDist = attach[:,attach[0].argsort()]\n",
    "        topK = sortDist[:,0:k]\n",
    "        topK = topK[1].astype(int)\n",
    "        counts = np.bincount(topK)\n",
    "        majority = np.argmax(counts)\n",
    "        y_pred = np.append(y_pred,majority)\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,X_test,Y_train, k):\n",
    "    y_pred = np.array([])\n",
    "    for point in X_test:\n",
    "        dist = np.array([])\n",
    "        for row in X_train:\n",
    "            d = np.sqrt(np.sum((point-row)**2))\n",
    "            dist = np.append(dist, d)\n",
    "        attach = np.vstack((dist, Y_train))\n",
    "        sortDist = attach[:,attach[0].argsort()]\n",
    "        topK = sortDist[:,0:k]\n",
    "        topK = topK[1].astype(int)\n",
    "        counts = np.bincount(topK)\n",
    "        majority = np.argmax(counts)\n",
    "        y_pred = np.append(y_pred,majority)\n",
    "    return y_pred\n",
    "        \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([])\n",
    "d = np.append(d, 2)\n",
    "np.append(d, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32717, 48)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8222, 48)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.05453693e-11, 7.40220849e-10, 1.33333209e-08, ...,\n",
       "        2.26442304e+00, 2.26442304e+00, 2.26472401e+00],\n",
       "       [3.36135556e-12, 4.44848981e-11, 1.18875409e-10, ...,\n",
       "        2.24340484e+00, 2.24340484e+00, 2.24340484e+00],\n",
       "       [9.96159844e-12, 5.88381044e-11, 1.97262025e-08, ...,\n",
       "        2.24340484e+00, 2.24340484e+00, 2.24370441e+00],\n",
       "       ...,\n",
       "       [3.03777346e-11, 5.93019904e-10, 1.76694123e-07, ...,\n",
       "        2.24670121e+00, 2.24670121e+00, 2.24670121e+00],\n",
       "       [1.55504036e-11, 7.38912160e-13, 2.53096281e-10, ...,\n",
       "        2.24640144e+00, 2.24610169e+00, 2.24640144e+00],\n",
       "       [3.88689903e-11, 4.35877244e-09, 1.11767184e-08, ...,\n",
       "        2.23622116e+00, 2.23652025e+00, 2.23622116e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "Make sure that plots are labeled and proper legends are used\n",
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
