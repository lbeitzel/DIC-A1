{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "training_ind = np.random.rand(len(data)) <= 0.8\n",
    "training = data[training_ind]\n",
    "testing = data[~training_ind]\n",
    "X_train = training[0:32734, 0:48]\n",
    "Y_train = training[0:32734, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:8222, 0:48]\n",
    "Y_test = testing[0:8222, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "#k = 5\n",
    "#print(KNN(X_train, X_test, Y_train, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0,1,1,2])\n",
    "y_pred = np.array([0,1,1,1])\n",
    "A = ConfusionMatrix(y_true,y_pred)\n",
    "B = np.array([])\n",
    "#display(A[0,:])\n",
    "#display(np.sum(A[0,:]))\n",
    "display(y_true.shape[0])\n",
    "display(y_true.shape[0]-1)\n",
    "acct = A[0,0]/(np.sum(A[0,:])\n",
    "#for i in range(y_true.shape[0]-1):\n",
    "#    acct = A[i,i]/(np.sum(A[i,:]))\n",
    "#    display(acct)\n",
    "#    B = np.append(B,acct)\n",
    "#display(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0,1,1,2])\n",
    "y_pred = np.array([0,1,1,1])\n",
    "A = ConfusionMatrix(y_true,y_pred)\n",
    "B = np.array([])\n",
    "display(A.shape)\n",
    "for i in range(A.shape[0]):\n",
    "    display(i)\n",
    "    sumRow = (np.sum(A[i,:]))\n",
    "    if sumRow == 0:\n",
    "        sumRow = 1\n",
    "    acct = A[i,i]/sumRow\n",
    "    B = np.append(B,acct)\n",
    "mean = np.mean(B)\n",
    "display(B, mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Recall(y_true,y_pred))\n",
    "display(Precision(y_true,y_pred))\n",
    "display(Accuracy(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_true,y_pred):\n",
    "    A = ConfusionMatrix(y_true,y_pred)\n",
    "    trueVal = np.sum(A.diagonal())\n",
    "    total = np.sum(A)\n",
    "    return trueVal/total\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "    A = ConfusionMatrix(y_true,y_pred)\n",
    "    B = np.array([])\n",
    "    for i in range(A.shape[0]):\n",
    "        sumCol = (np.sum(A[:,i]))\n",
    "        if sumCol == 0:\n",
    "            sumCol = 1\n",
    "        acct = A[i,i]/sumCol\n",
    "        B = np.append(B,acct)\n",
    "    mean = np.mean(B)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true,y_pred):\n",
    "    A = ConfusionMatrix(y_true,y_pred)\n",
    "    B = np.array([])\n",
    "    for i in range(A.shape[0]):\n",
    "        sumRow = (np.sum(A[i,:]))\n",
    "        if sumRow == 0:\n",
    "            sumRow = 1\n",
    "        acct = A[i,i]/sumRow\n",
    "        B = np.append(B,acct)\n",
    "    mean = np.mean(B)\n",
    "    return mean\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    numClass = np.unique(y_true).shape[0]\n",
    "    C = y_true*numClass + y_pred\n",
    "    C = np.bincount(C)\n",
    "    C = np.pad(C, (0, numClass**2-C.shape[0]), 'constant')\n",
    "    D = C.reshape(numClass,numClass)\n",
    "    return np.transpose(D)\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0,1,1,2])\n",
    "y_pred = np.array([0,1,1,1])\n",
    "#display(y_true)\n",
    "#display(np.unique(y_true))\n",
    "numClass = np.unique(y_true).shape[0]\n",
    "#display(numClass)\n",
    "C = y_true*numClass + y_pred\n",
    "C = np.bincount(C)\n",
    "C = np.pad(C, (0, numClass**2-C.shape[0]), 'constant')\n",
    "#display(C)\n",
    "D = C.reshape(numClass,numClass)\n",
    "#display(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training[0:800, 0:20]\n",
    "Y_train = training[0:800, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:200, 0:20]\n",
    "Y_test = testing[0:200, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "k = 10\n",
    "\n",
    "y_pred = np.array([])\n",
    "for point in X_test:\n",
    "        dist = np.array([])\n",
    "        for row in X_train:\n",
    "            d = np.sqrt(np.sum((point-row)**2))\n",
    "            dist = np.append(dist, d)\n",
    "        attach = np.vstack((dist, Y_train))\n",
    "        sortDist = attach[:,attach[0].argsort()]\n",
    "        topK = sortDist[:,0:k]\n",
    "        topK = topK[1].astype(int)\n",
    "        counts = np.bincount(topK)\n",
    "        majority = np.argmax(counts)\n",
    "        y_pred = np.append(y_pred,majority)\n",
    "        \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([[[1,4,5,6],[7,2,5,5],[3,1,4,2]],[[3,5,6,5],[5,2,7,3],[8,6,1,2]]])\n",
    "display(mat)\n",
    "#mat_sort = mat[mat[:,2].argsort()[::-1]]\n",
    "#mat = mat[np.arange(len(mat))[:,np.newaxis]]\n",
    "#m = mat.view(dtype=[('', mat.dtype)]*mat.shape[-1])\n",
    "#m.sort(axis=1)\n",
    "#mat\n",
    "I, J, K = np.ogrid[tuple(map(slice, mat.shape))]\n",
    "# I, J, K are the identity indices in the sense that (A == A[I, J, K]).all()\n",
    "newK = np.argsort(mat[0],axis=-1) # first axis of A[1] is second axis of A\n",
    "display(mat[I, J, newK])\n",
    "#display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,4,5,6,7],[7,2,5,5,3],[3,1,4,2,7],[6,2,4,2,7]])\n",
    "#A = np.transpose(A)\n",
    "B = np.array([[3,5,6,5,2],[5,2,7,3,1],[8,6,1,2,2],[5,2,2,2,5]])\n",
    "#B = np.transpose(B)\n",
    "C = np.array([A, B])\n",
    "I, J, K = np.ogrid[tuple(map(slice, C.shape))]\n",
    "# I, J, K are the identity indices in the sense that (A == A[I, J, K]).all()\n",
    "newK = np.argsort(C[0],axis=-1) # first axis of A[1] is second axis of A\n",
    "display(C[I, J, newK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[3,1,6]])\n",
    "display(A)\n",
    "B = np.array([[2,7,2],[8,2,4]])\n",
    "display(B)\n",
    "C = np.true_divide(A,B)\n",
    "display(C)\n",
    "mini = np.min(A,axis = 0)\n",
    "maxi = np.max(A,axis = 0)\n",
    "#display(mini)\n",
    "min2 = np.tile(mini, (A.shape[0],1))\n",
    "#display(min2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1],\n",
       "       [4, 5, 1],\n",
       "       [2, 3, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1],\n",
       "       [2, 1, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 1]],\n",
       "\n",
       "       [[2, 1, 2]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[2, 4, 2],\n",
       "        [5, 7, 2],\n",
       "        [3, 5, 2]],\n",
       "\n",
       "       [[3, 3, 3],\n",
       "        [6, 6, 3],\n",
       "        [4, 4, 3]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8, 14, 10],\n",
       "       [ 9, 15, 11]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.array([[1,2,1],[4,5,1],[2,3,1]])\n",
    "display(A)\n",
    "B = np.array([[1,2,1],[2,1,2]])\n",
    "display(B)\n",
    "B_new = B[:,np.newaxis]\n",
    "display(B_new)\n",
    "C = A+B_new\n",
    "display(C)\n",
    "display(B_new.shape)\n",
    "C = np.sum(C,axis=2)\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X_train.shape, X_test.shape)\n",
    "X_min = np.min(X_train,axis = 0)\n",
    "X_max = np.max(X_train,axis = 0)\n",
    "X_minMat = np.tile(X_min, (X_train.shape[0],1))\n",
    "X_maxMat = np.tile(X_max, (X_train.shape[0],1))\n",
    "X_train_normal = np.true_divide(X_train-X_minMat, X_maxMat-X_minMat)\n",
    "\n",
    "\n",
    "X_min2 = np.min(X_test,axis = 0)\n",
    "X_max2 = np.max(X_test,axis = 0)\n",
    "X_minMat2 = np.tile(X_min2, (X_test.shape[0],1))\n",
    "X_maxMat2 = np.tile(X_max2, (X_test.shape[0],1))\n",
    "X_test_normal = np.true_divide(X_test-X_minMat2, X_maxMat2-X_minMat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.56154869, 4.62418325, 4.30597545, ..., 4.59311981, 4.52319435,\n",
       "        4.40996669],\n",
       "       [4.58427501, 4.64865525, 4.32998554, ..., 4.61786109, 4.54721027,\n",
       "        4.42933797],\n",
       "       [4.46773207, 4.53164515, 4.21312257, ..., 4.50045221, 4.43044681,\n",
       "        4.31401073],\n",
       "       ...,\n",
       "       [5.11803095, 5.18198247, 4.86339949, ..., 5.15119867, 5.08058677,\n",
       "        4.9634763 ],\n",
       "       [3.176862  , 3.24036528, 2.92186272, ..., 3.20974969, 3.13915709,\n",
       "        3.0250442 ],\n",
       "       [4.15079006, 4.21377148, 3.89544712, ..., 4.18283608, 4.1126884 ,\n",
       "        3.99886568]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(200, 800)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 3.78733215,  3.86520559,  3.86680905, ...,  5.99440856,\n",
       "          5.9983311 ,  6.0059101 ],\n",
       "        [ 3.81192134,  3.88705305,  3.88706154, ...,  6.01582054,\n",
       "          6.01976314,  6.02736625],\n",
       "        [ 3.6944891 ,  3.77077795,  3.77234789, ...,  5.89977181,\n",
       "          5.90370438,  5.91128966],\n",
       "        ...,\n",
       "        [ 4.34523964,  4.42092601,  4.42122706, ...,  6.54983161,\n",
       "          6.55377285,  6.56137866],\n",
       "        [ 2.40386772,  2.48023586,  2.48183471, ...,  4.60944312,\n",
       "          4.6133699 ,  4.62095523],\n",
       "        [ 3.37697442,  3.45429189,  3.45589164, ...,  5.58350024,\n",
       "          5.58742548,  5.5950075 ]],\n",
       "\n",
       "       [[10.        ,  3.        ,  3.        , ...,  4.        ,\n",
       "          4.        ,  4.        ],\n",
       "        [10.        ,  7.        ,  3.        , ...,  4.        ,\n",
       "          4.        ,  4.        ],\n",
       "        [10.        ,  3.        ,  3.        , ...,  4.        ,\n",
       "          4.        ,  4.        ],\n",
       "        ...,\n",
       "        [10.        ,  3.        ,  7.        , ...,  4.        ,\n",
       "          4.        ,  4.        ],\n",
       "        [10.        ,  3.        ,  3.        , ...,  4.        ,\n",
       "          4.        ,  4.        ],\n",
       "        [10.        ,  3.        ,  3.        , ...,  4.        ,\n",
       "          4.        ,  4.        ]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10.,  3.,  3.,  7.,  7.,  7.],\n",
       "       [10.,  7.,  3.,  3.,  7.,  7.],\n",
       "       [10.,  3.,  3.,  7.,  7.,  7.],\n",
       "       ...,\n",
       "       [10.,  3.,  7.,  3.,  7.,  7.],\n",
       "       [10.,  3.,  3.,  7.,  7.,  7.],\n",
       "       [10.,  3.,  3.,  7.,  7.,  7.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  3,  3,  7,  7,  7],\n",
       "       [10,  7,  3,  3,  7,  7],\n",
       "       [10,  3,  3,  7,  7,  7],\n",
       "       ...,\n",
       "       [10,  3,  7,  3,  7,  7],\n",
       "       [10,  3,  3,  7,  7,  7],\n",
       "       [10,  3,  3,  7,  7,  7]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EUCLIDEAN\n",
    "X_train = training[0:800, 0:20]\n",
    "Y_train = training[0:800, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:200, 0:20]\n",
    "Y_test = testing[0:200, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "X_train_normal = X_train\n",
    "X_test_normal = X_test\n",
    "\n",
    "A2 = np.square(X_train_normal)\n",
    "B2 = np.square(X_test_normal)\n",
    "B2_new = B2[:,np.newaxis]\n",
    "A2andB2 = A2+B2_new\n",
    "A2andB2 = np.sum(A2andB2,axis=2)\n",
    "X_train_normalnew = np.transpose(X_train_normal)\n",
    "AB2 = np.multiply(2, np.dot(X_test_normal,X_train_normalnew))\n",
    "Euclidean = np.sqrt(A2andB2 + AB2)\n",
    "display(Euclidean, Euclidean.shape)\n",
    "\n",
    "k = 6\n",
    "trueLabel = np.tile(Y_train, (X_test_normal.shape[0],1))\n",
    "Dist = np.array([Euclidean, trueLabel])\n",
    "\n",
    "I, J, K = np.ogrid[tuple(map(slice, Dist.shape))]\n",
    "# I, J, K are the identity indices in the sense that (A == A[I, J, K]).all()\n",
    "newK = np.argsort(Dist[0],axis=-1) # first axis of A[1] is second axis of A\n",
    "Dist = Dist[I, J, newK]\n",
    "#a,b = (X_test.shape[0],X_train.shape[0])\n",
    "display(Dist)\n",
    "topK = Dist[1,:,0:k]\n",
    "display(topK)\n",
    "#display(topK)\n",
    "topK = topK.astype(int)\n",
    "display(topK)\n",
    "#display(topK)\n",
    "Y_pred = np.array([])\n",
    "for vector in topK:\n",
    "    counts = np.bincount(vector)\n",
    "    majority = np.argmax(counts)\n",
    "    Y_pred = np.append(Y_pred,majority)\n",
    "display(Y_pred.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "display(accuracy_score(y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.06712859e-02, 1.08226540e-02, 1.10574405e-02, ...,\n",
       "         2.92841730e-01, 2.94245422e-01, 2.97682827e-01],\n",
       "        [7.90492197e-03, 8.26470993e-03, 8.48467208e-03, ...,\n",
       "         4.18210192e-01, 4.18645364e-01, 4.21285074e-01],\n",
       "        [1.17698566e-02, 1.25708989e-02, 1.27096657e-02, ...,\n",
       "         3.01783358e-01, 3.02470321e-01, 3.03002709e-01],\n",
       "        ...,\n",
       "        [1.24217951e-02, 1.28415148e-02, 1.28456472e-02, ...,\n",
       "         2.77452034e-01, 2.79875776e-01, 2.87272537e-01],\n",
       "        [1.14967993e-02, 1.28375296e-02, 1.28740186e-02, ...,\n",
       "         2.35169962e-01, 2.45143444e-01, 2.65554642e-01],\n",
       "        [1.65136654e-02, 1.71756100e-02, 1.76578767e-02, ...,\n",
       "         2.67775242e-01, 2.70404970e-01, 2.78732080e-01]],\n",
       "\n",
       "       [[6.00000000e+00, 9.00000000e+00, 9.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01],\n",
       "        [3.00000000e+00, 8.00000000e+00, 3.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01],\n",
       "        ...,\n",
       "        [9.00000000e+00, 9.00000000e+00, 9.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01],\n",
       "        [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 8.00000000e+00, ...,\n",
       "         1.10000000e+01, 1.10000000e+01, 1.10000000e+01]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[6., 9., 9., 6., 6., 6.],\n",
       "       [3., 3., 3., 4., 5., 3.],\n",
       "       [3., 8., 3., 9., 3., 8.],\n",
       "       ...,\n",
       "       [9., 9., 9., 9., 9., 9.],\n",
       "       [2., 2., 2., 2., 2., 2.],\n",
       "       [8., 8., 8., 8., 1., 6.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 9, 9, 6, 6, 6],\n",
       "       [3, 3, 3, 4, 5, 3],\n",
       "       [3, 8, 3, 9, 3, 8],\n",
       "       ...,\n",
       "       [9, 9, 9, 9, 9, 9],\n",
       "       [2, 2, 2, 2, 2, 2],\n",
       "       [8, 8, 8, 8, 1, 6]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#COSINE GARBAGE ABSOLUTE TRAHS\n",
    "X_train = training[0:8000, 0:48]\n",
    "Y_train = training[0:8000, 48:49]\n",
    "Y_train = Y_train.flatten()\n",
    "X_test = testing[0:2000, 0:48]\n",
    "Y_test = testing[0:2000, 48:49]\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "#display(X_train.shape, X_test.shape)\n",
    "X_min = np.min(X_train,axis = 0)\n",
    "X_max = np.max(X_train,axis = 0)\n",
    "X_minMat = np.tile(X_min, (X_train.shape[0],1))\n",
    "X_maxMat = np.tile(X_max, (X_train.shape[0],1))\n",
    "X_train_normal = np.true_divide(X_train-X_minMat, X_maxMat-X_minMat)\n",
    "\n",
    "X_min2 = np.min(X_test,axis = 0)\n",
    "X_max2 = np.max(X_test,axis = 0)\n",
    "X_minMat2 = np.tile(X_min2, (X_test.shape[0],1))\n",
    "X_maxMat2 = np.tile(X_max2, (X_test.shape[0],1))\n",
    "X_test_normal = np.true_divide(X_test-X_minMat2, X_maxMat2-X_minMat2)\n",
    "#display(X_train_normal.shape, X_test_normal.shape)\n",
    "\n",
    "X_train_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_train_normal)\n",
    "X_test_L1norm = np.apply_along_axis(np.linalg.norm, 1, X_test_normal)\n",
    "#display(X_train_L1norm.shape, X_test_L1norm.shape)\n",
    "\n",
    "C = np.transpose(np.tile(X_train_L1norm, (X_train.shape[1],1)))\n",
    "D = np.transpose(np.tile(X_test_L1norm, (X_test.shape[1],1)))\n",
    "#display(C.shape,D.shape)\n",
    "\n",
    "X_train_final = np.true_divide(X_train_normal,C)\n",
    "X_test_final = np.true_divide(X_test_normal,D)\n",
    "\n",
    "X_train_final = np.transpose(X_train_final)\n",
    "#display(X_test_final.shape, X_train_final.shape)\n",
    "\n",
    "dist = np.dot(X_test_final, X_train_final)\n",
    "k = 6\n",
    "trueLabel = np.tile(Y_train, (X_test_final.shape[0],1))\n",
    "ones = np.ones((X_test.shape[0],X_train.shape[0]))\n",
    "Dist = np.subtract(ones,dist)\n",
    "Dist = np.array([Dist, trueLabel])\n",
    "\n",
    "I, J, K = np.ogrid[tuple(map(slice, Dist.shape))]\n",
    "# I, J, K are the identity indices in the sense that (A == A[I, J, K]).all()\n",
    "newK = np.argsort(Dist[0],axis=-1) # first axis of A[1] is second axis of A\n",
    "Dist = Dist[I, J, newK]\n",
    "#a,b = (X_test.shape[0],X_train.shape[0])\n",
    "display(Dist)\n",
    "topK = Dist[1,:,0:k]\n",
    "display(topK)\n",
    "#display(topK)\n",
    "topK = topK.astype(int)\n",
    "display(topK)\n",
    "#display(topK)\n",
    "Y_pred = np.array([])\n",
    "for vector in topK:\n",
    "    counts = np.bincount(vector)\n",
    "    majority = np.argmax(counts)\n",
    "    Y_pred = np.append(Y_pred,majority)\n",
    "display(Y_pred.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "display(accuracy_score(y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = Dist[:,0:k,:]\n",
    "#display(topK)\n",
    "topK = topK[:,:,1].astype(int)\n",
    "#display(topK)\n",
    "Y_pred = np.array([])\n",
    "for vector in topK:\n",
    "    counts = np.bincount(vector)\n",
    "    majority = np.argmax(counts)\n",
    "    Y_pred = np.append(Y_pred,majority)\n",
    "#display(Y_pred)\n",
    "#=sortDist = np.sort(sortDist, axis = 2)\n",
    "#display(sortDist)\n",
    "#sortDist = sorted(data, key=lambda x: x[1])\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = Y_test\n",
    "display(y_true.shape)\n",
    "display(Y_pred.shape)\n",
    "display(accuracy_score(y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,X_test,Y_train, k):\n",
    "    y_pred = np.array([])\n",
    "    for point in X_test:\n",
    "        dist = np.array([])\n",
    "        for row in X_train:\n",
    "            d = np.sqrt(np.sum((point-row)**2))\n",
    "            dist = np.append(dist, d)\n",
    "        attach = np.vstack((dist, Y_train))\n",
    "        sortDist = attach[:,attach[0].argsort()]\n",
    "        topK = sortDist[:,0:k]\n",
    "        topK = topK[1].astype(int)\n",
    "        counts = np.bincount(topK)\n",
    "        majority = np.argmax(counts)\n",
    "        y_pred = np.append(y_pred,majority)\n",
    "    return y_pred\n",
    "        \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    ##NP.tile np.repeat\n",
    "    ##np.lin(norx)\n",
    "    ##creating a matrix with same test row repeating operation on entire train matrix\n",
    "    ##(A-B)^2 = A^2 - 2AB + B^2\n",
    "    ##cosine distance also an option\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([])\n",
    "d = np.append(d, 2)\n",
    "np.append(d, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    \n",
    "    #1) Choose the number of clusters (K = N)\n",
    "    \n",
    "    #2) Initialize N centroids to \"random\" values of the data,\n",
    "    #Either choose them at random: (Find the min and max of the data, then calculate random coordinates from there)\n",
    "    #Or sort the dataset, split it into K portions and pick one datapoint from each portion as a centriod.\n",
    "    \n",
    "    #3) Reassign all points to the closest centroid\n",
    "    #Calculate Euclidean distance between each point and each centroid, assign each point to the min dist centroid\n",
    "    \n",
    "    #4) Recalculate centroid coordinate based on point assignment\n",
    "    #New centroid value is the average of all point that currently have that centroid's label\n",
    "    \n",
    "    #5) Repeat steps 3 and 4 until there is no change in centroid coordinates, or points stop switching clusters\n",
    "    #Either keep track and only stop is all of the centroids don't change values\n",
    "    #Or only repeat a fixed number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "Make sure that plots are labeled and proper legends are used\n",
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
